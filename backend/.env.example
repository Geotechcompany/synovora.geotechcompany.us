# Google Gemini (preferred) or NVIDIA NIM credentials for AI post generation
GEMINI_API_KEY=your_gemini_api_key_here

# NVIDIA fallback (set when using NVIDIA instead of Gemini)
NVIDIA_API_KEY=your_nvidia_api_key_here
NVIDIA_BASE_URL=https://integrate.api.nvidia.com/v1
NVIDIA_MODEL=meta/llama-3.1-70b-instruct

# LinkedIn OAuth 2.0 Access Token
# Get this from LinkedIn Developer Portal after OAuth flow
LINKEDIN_TOKEN=your_linkedin_access_token_here

# LinkedIn Profile URN
# Format: urn:li:person:abc123xyz
# You can get this from your LinkedIn profile or API
PROFILE_URN=urn:li:person:your_profile_id_here

# LinkedIn OAuth App Credentials (for OAuth flow)
# Optional - only needed if implementing full OAuth flow
LINKEDIN_CLIENT_ID=your_linkedin_client_id_here
LINKEDIN_CLIENT_SECRET=your_linkedin_client_secret_here
LINKEDIN_REDIRECT_URI=http://localhost:8000/auth/callback

# Server Configuration
PORT=8000

# Frontend URL (used for OAuth success redirects back to the dashboard)
FRONTEND_URL=http://localhost:5173

# Encryption key for storing sensitive per-user secrets (e.g., OpenAI API key) in Supabase.
# Generate with:
#   python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
APP_ENCRYPTION_KEY=

# Optional: audience validation for Clerk JWTs (leave empty to skip aud verification).
CLERK_AUDIENCE=

# Post scheduling (backend worker)
SCHEDULER_ENABLED=1
SCHEDULER_POLL_SECONDS=20

# Supabase (Postgres) Configuration
SUPABASE_URL=https://your-project-ref.supabase.co
# Use a Service Role key for backend/server usage (recommended).
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key_here
# Optional: used only if service role key isn't provided.
SUPABASE_ANON_KEY=

# Optional override table names
SUPABASE_POSTS_TABLE=posts
SUPABASE_USERS_TABLE=clerk_users

# Supabase Storage (for post images)
SUPABASE_STORAGE_BUCKET=linkedinimages

# Dropbox (optional) â€“ used for post images when set; takes precedence over Supabase if both are set
DROPBOX_ACCESS_TOKEN=your_dropbox_access_token_here
DROPBOX_IMAGE_FOLDER=/Synvora/post-images

# OpenAI fallback (optional). If a user stores their own key, that one is preferred.
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini

# Development fallback: if MongoDB cannot connect, store posts/users locally on disk.
# This prevents the API from returning 503 for persistence endpoints while offline / DNS-blocked.
PERSISTENCE_ALLOW_FILE_FALLBACK=0
# Optional override paths (default: backend/posts.json and backend/clerk_users.json)
FILE_POSTS_PATH=
FILE_USERS_PATH=

# Hugging Face Image Generation
HF_TOKEN=your_huggingface_api_key_here
HF_IMAGE_MODEL=black-forest-labs/FLUX.1-dev
HF_PROVIDER=nebius

# Serper.dev (Google SERP) for live trend research
SERPER_API_KEY=your_serper_api_key_here
SERPER_BASE_URL=https://google.serper.dev/search

# LinkedIn headless scraper (uses linkedin-profile-scraper-api)
LINKEDIN_SCRAPER_LI_AT=your_li_at_cookie_value
LINKEDIN_SCRAPER_PROFILE_URL=https://www.linkedin.com/in/your-vanity-slug/
LINKEDIN_SCRAPER_TIMEOUT=45000

# SMTP / Gmail email delivery
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=your_gmail_address@gmail.com
SMTP_PASSWORD=your_gmail_app_password
EMAIL_FROM=your_gmail_address@gmail.com

# Cron automation: max users processed per /cron/run-automation call (default 1). Use 1 on 512MB instances to avoid OOM.
CRON_AUTOMATION_MAX_USERS_PER_RUN=1
# Set to 1 to skip image generation on cron (drafts created without image). Leave unset to generate images when OPENAI_API_KEY is set.
# CRON_AUTOMATION_SKIP_IMAGE=1
# Visibility for auto-published posts (when user enables "Publish to LinkedIn automatically" in Automations): PUBLIC or CONNECTIONS (default PUBLIC).
# CRON_AUTOMATION_PUBLISH_VISIBILITY=PUBLIC

